{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Module.Global_variable import os, time, torch, np, pd, plt\n",
    "\n",
    "from Module.utils.Convenience_Function import save_pickle, draw_img_and_bbox_torch_style, time_checker\n",
    "\n",
    "import Module.process1.preparatory_items as p1pi\n",
    "from Module.process1.index_dictionary_maker import get_index_dictionary\n",
    "from Module.process1.torch_dataset import get_my_dataLoader\n",
    "from Module.process1.torch_basic_style_model import get_my_torch_model, get_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 시작 전 정의 사항\n",
    "#####################################################################################\n",
    "# directory 생성\n",
    "_MAKE_NEW_DIRECTORY = False\n",
    "# Index dictionary를 새로 생성할 것인지\n",
    "_MAKE_NEW_INDEX_DICT = False\n",
    "# Log를 출력할 것인지\n",
    "_VERBOSE = True\n",
    "# 사용할 GPU 번호\n",
    "_GPU_NUMBER = 3\n",
    "torch.cuda.set_device(_GPU_NUMBER)   # set basic gpu\n",
    "# torch._dynamo 캐시 한계치 조정\n",
    "torch._dynamo.config.cache_size_limit = 64   # Default\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "# 학습 간 전역 변수 설정\n",
    "#####################################################################################\n",
    "# process 기초 디렉터리 생성\n",
    "p1pi.make_process_start_dir(makes_new=_MAKE_NEW_DIRECTORY)\n",
    "\n",
    "# index dictionary with Data Loader\n",
    "_IDX_DICT = get_index_dictionary(process_boolean=_MAKE_NEW_INDEX_DICT).process()\n",
    "_LOADER = get_my_dataLoader(_IDX_DICT)\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "# Model 학습 관련 변수 설정\n",
    "#####################################################################################\n",
    "_PROCESS_SET_DICT = p1pi.get_process_set_dict(\n",
    "    save_iter_time_log=True,   # iteration의 time log 저장 여부\n",
    "    verbose=_VERBOSE\n",
    ")\n",
    "_MODEL_SET_DICT = p1pi.get_model_set_dict(\n",
    "    model_key=\"faster_fpn\",\n",
    "    faster_bb_key=\"resnet50_v2\",\n",
    "    optimizer_key=\"Adam\"\n",
    ")\n",
    "_HYPER_PARAMS_DICT = p1pi.get_HP_set_dict(\n",
    "    learing_rate=0.00005, weight_decay=0.005,\n",
    "    T_0=20, T_mult=2, eta_min=0.0000001\n",
    ")\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys, time, json\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from Module.utils.Convenience_Function import time_checker\n",
    "from Module.utils.Convenience_Function_by_torch import torch_device, state_dict_to_np_array_dict\n",
    "from Module.utils.log_utils import my_progressbar_time_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_handler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.loss = []\n",
    "        self.loss_classifier = []\n",
    "        self.loss_box_reg = []\n",
    "        self.loss_objectness = []\n",
    "        self.loss_rpn_box_reg = []\n",
    "        \n",
    "        \n",
    "    def loss_stack(self, loss_dict):\n",
    "        \n",
    "        self.loss.append(sum(loss for loss in loss_dict.values()).item())\n",
    "        self.loss_classifier.append(loss_dict['loss_classifier'].item())\n",
    "        self.loss_box_reg.append(loss_dict['loss_box_reg'].item())\n",
    "        self.loss_objectness.append(loss_dict['loss_objectness'].item())\n",
    "        self.loss_rpn_box_reg.append(loss_dict['loss_rpn_box_reg'].item())\n",
    "        \n",
    "        \n",
    "    def calculate_loss_averate(self):\n",
    "        result = {\n",
    "            \"loss\":np.mean(self.loss),\n",
    "            \"loss_classifier\":np.mean(self.loss_classifier),\n",
    "            \"loss_box_reg\":np.mean(self.loss_box_reg),\n",
    "            \"loss_objectness\":np.mean(self.loss_objectness),\n",
    "            \"loss_rpn_box_reg\":np.mean(self.loss_rpn_box_reg),\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def make_loss_sentence(self, aver_loss_dict, spend_time):\n",
    "        loss_sentence = \" [time] %s [Loss] total: %s, classifier: %s, box_reg: %s, objectness: %s, rpn_box_reg: %s\" % (\n",
    "            spend_time,\n",
    "            \"{:1.4f}\".format(aver_loss_dict[\"loss\"]),\n",
    "            \"{:1.4f}\".format(aver_loss_dict[\"loss_classifier\"]),\n",
    "            \"{:1.4f}\".format(aver_loss_dict[\"loss_box_reg\"]),\n",
    "            \"{:1.4f}\".format(aver_loss_dict[\"loss_objectness\"]),\n",
    "            \"{:1.4f}\".format(aver_loss_dict[\"loss_rpn_box_reg\"])\n",
    "        )\n",
    "        return loss_sentence\n",
    "    \n",
    "    \n",
    "    def make_loss_log(self):\n",
    "        result = {\n",
    "        \"loss\":self.loss,\n",
    "        \"loss_classifier\":self.loss_classifier,\n",
    "        \"loss_box_reg\":self.loss_box_reg,\n",
    "        \"loss_objectness\":self.loss_objectness,\n",
    "        \"loss_rpn_box_reg\":self.loss_rpn_box_reg\n",
    "        }\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class model_train_and_evaluate:\n",
    "    \n",
    "    \n",
    "    def __init__(self, p_set_dict, m_set_dict, hp_dict, loader, gpu_num, use_compile=False, log_freq=5):\n",
    "        \n",
    "        self.p_set_dict = p_set_dict\n",
    "        self.m_set_dict = m_set_dict\n",
    "        self.hp_dict = hp_dict\n",
    "        self.loader = loader\n",
    "        self.gpu_num = gpu_num\n",
    "        self.device = torch_device().get_device(gpu_number=gpu_num)\n",
    "        self.use_compile = use_compile\n",
    "        self.log_freq = log_freq\n",
    "        \n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "        self.test_loader = None\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.scaler = None\n",
    "        self.train_log_path = None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def import_model(self):\n",
    "        # Model 정의\n",
    "        model = get_my_torch_model(\n",
    "            class_num=self.m_set_dict['num_class'],\n",
    "            model_key=self.m_set_dict['model_key'],\n",
    "            faster_bb_key=self.m_set_dict['faster_bb_key']\n",
    "        ).process().to(self.device)\n",
    "        # torch 2.0의 compile 사용 여부 - Object detection model에서 속도가 느려지는 이슈가 있었음.\n",
    "        self.model = torch.compile(model) if self.use_compile else model\n",
    "        \n",
    "        \n",
    "        \n",
    "    def import_optimizer_and_scheduler(self):\n",
    "        \n",
    "        # Optimizer 정의\n",
    "        self.optimizer = get_optimizer(\n",
    "            self.model,\n",
    "            learning_rate = self.hp_dict['learning_rate'],\n",
    "            weight_decay=self.hp_dict['weight_decay'],\n",
    "            opt_key=self.m_set_dict['optimizer']\n",
    "        )\n",
    "        # Scheduler 정의\n",
    "        self.scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer=self.optimizer,\n",
    "            T_0=self.hp_dict['T_0'],\n",
    "            T_mult=self.hp_dict['T_mult'],\n",
    "            eta_min=self.hp_dict['eta_min']\n",
    "        )\n",
    "        # scaler(AMP) 정의 - Autocast 후 Gradient scaling 적용.\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    # 학습 관련 코드\n",
    "    #################################################################################\n",
    "    def model_train_process(self, epoch):\n",
    "        \n",
    "        # Log Instance 생성\n",
    "        Log_Ins = my_progressbar_time_log(\n",
    "            header=\"Epochs: %i/%i\" % (epoch+1, self.m_set_dict[\"epochs\"]),\n",
    "            verbose=self.p_set_dict['verbose'],\n",
    "            sep_next=False\n",
    "        )\n",
    "        # Loss 전처리기 Instance 생성\n",
    "        Loss_Ins = loss_handler()\n",
    "        \n",
    "        self.model.train()   # model train\n",
    "        \n",
    "        start_time = time.time()\n",
    "        iteration = 0\n",
    "        for imgs, targets in Log_Ins.with_time_log(self.train_loader):\n",
    "\n",
    "            # 1. upload to device\n",
    "            imgs = self.image_list_upload_to_device(img_list=imgs)\n",
    "            targets = self.target_list_upload_to_device(target_list=targets)\n",
    "\n",
    "            # 2. model training - AMP\n",
    "            with torch.cuda.amp.autocast(enabled=self.m_set_dict[\"use_AMP\"]):\n",
    "                loss_dict = self.model(imgs, targets)\n",
    "                # sum all loss_dict's loss(loss_classification, loss_box_reg, loss_objectness, loss_rpn_box_reg)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                \n",
    "            # 3. back propagation\n",
    "            self.back_propagation(losses)\n",
    "\n",
    "            # 4. Log\n",
    "            if self.p_set_dict['save_iter_time_log']:\n",
    "                log = self.make_iteration_time_log(epoch, iteration, time_log_ins=Log_Ins)\n",
    "            # 4.1. Loss 정리 - Log로 출력 또는 \n",
    "            Loss_Ins.loss_stack(loss_dict)\n",
    "            iteration += 1\n",
    "\n",
    "        if self.p_set_dict['verbose']:\n",
    "            print(Loss_Ins.make_loss_sentence(Loss_Ins.calculate_loss_averate(), time_checker(start_time)))\n",
    "            \n",
    "        return Loss_Ins\n",
    "    \n",
    "    \n",
    "    \n",
    "    def image_list_upload_to_device(self, img_list):\n",
    "        # mini-batch의 image들은 list로 묶여 있음. 각각 .to(device) 정의\n",
    "        return [img.to(self.device) for img in img_list]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def target_list_upload_to_device(self, target_list):\n",
    "        result = []\n",
    "        for target in target_list:\n",
    "            device_dict = dict()\n",
    "            for key, value in target.items():\n",
    "                device_dict[key] = value.to(self.device) if isinstance(value, torch.Tensor) else value\n",
    "            result.append(device_dict)\n",
    "        return result\n",
    "                \n",
    "        \n",
    "        \n",
    "    def back_propagation(self, losses):\n",
    "        self.optimizer.zero_grad()\n",
    "        # 3.1. AMP - GradScale use or not\n",
    "        if self.m_set_dict[\"use_AMP\"]:\n",
    "            self.gradient_scaled_parameter_update_with_clipping(losses=losses)\n",
    "        else:\n",
    "            self.parameter_update_with_clipping(losses=losses)\n",
    "        # 3.2. step scheduler - CosinAnnelingWarmRestarts(Iterantion scheduler)\n",
    "        self.scheduler.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def gradient_scaled_parameter_update_with_clipping(self, losses):\n",
    "        # Gradient scaling with back propagation\n",
    "        self.scaler.scale(losses).backward()\n",
    "        # Gradient update 전에 Gradient clipping 적용\n",
    "        #################################################################\n",
    "        # AMP 사용 시, Gradient clipping은 scaling 역산 후 적용되어야 한다.\n",
    "        self.scaler.unscale_(self.optimizer) # Scaling 역산\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            self.model.parameters(), max_norm=self.m_set_dict['max_norm']\n",
    "        )\n",
    "        #################################################################\n",
    "        # The parameters are updated using a scaled gradient\n",
    "        self.scaler.step(self.optimizer)\n",
    "        # scaler update\n",
    "        self.scaler.update()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def parameter_update_with_clipping(self, losses):\n",
    "        losses.backward()\n",
    "        # Gradient update 전 Gradient clipping 적용\n",
    "        #################################################################\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            self.model.parameters(), max_norm=self.m_set_dict['max_norm']\n",
    "        )\n",
    "        ################################################################\n",
    "        # parameter update\n",
    "        self.optimizer.step()\n",
    "    #################################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Log 관련 코드\n",
    "    #################################################################################\n",
    "    # []로 구성된 json log 파일 생성\n",
    "    def make_log_file(self, k):\n",
    "        if self.p_set_dict['save_iter_time_log']:\n",
    "            self.train_log_path = self.p_set_dict['train_log_key'] + \"_\" + str(self.gpu_num) + f\"_{k}.json\"\n",
    "            with open(self.train_log_path, 'w') as file:\n",
    "                json.dump([], file)\n",
    "        \n",
    "        \n",
    "    # 한 iteration에 대한 시간 log 생성\n",
    "    def make_iteration_time_log(self, epoch, iteration, time_log_ins):\n",
    "        # log_instance의 time들을 모두 해당 시점으로 update한다.\n",
    "        time_log_dict = time_log_ins.put_it_at_the_end_of_the_iteration_process()\n",
    "        # log 생성\n",
    "        if (iteration%self.log_freq == 0) or (iteration==time_log_ins.iter_size-1):\n",
    "            log = self.iter_log_dictionary_maker(epoch, iteration, time_log_dict)\n",
    "            self.overwrite_train_log(log)\n",
    "\n",
    "            \n",
    "    # log 파일을 불러와서 신규 로그를 추가한다.\n",
    "    def overwrite_train_log(self, log):\n",
    "\n",
    "        # json file을 읽는다.\n",
    "        with open(self.train_log_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        # 신규 log 추가\n",
    "        data.append(log)\n",
    "        # 변경된 내용 저장\n",
    "        with open(self.train_log_path, 'w') as file:\n",
    "            json.dump(data, file)  # indent=4는 들어쓰기로, json의 가독성을 올려준다.\n",
    "            \n",
    "            \n",
    "    # log dictionary를 만든다.\n",
    "    def iter_log_dictionary_maker(self, epoch, iteration, time_log_dict):\n",
    "\n",
    "        log = dict()\n",
    "        log[\"epoch\"] = epoch\n",
    "        log[\"iteration\"] = iteration\n",
    "        log[\"lr\"] = \"{:1.8f}\".format(self.optimizer.param_groups[0][\"lr\"])\n",
    "        # 시간 관련 변수 추가\n",
    "        log[\"eta\"] = time_log_dict['eta']\n",
    "        log[\"elapsed\"] = time_log_dict['stack']\n",
    "        log[\"load\"] = time_log_dict['data_load']\n",
    "        log[\"iter_train\"] = time_log_dict['iter_train']\n",
    "        return log\n",
    "    #################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(_PROCESS_SET_DICT[\"k_size\"]):\n",
    "    \n",
    "    # Model 학습을 위한 Instance 생성\n",
    "    MTnE_Ob = model_train_and_evaluate(\n",
    "        p_set_dict=_PROCESS_SET_DICT, m_set_dict=_MODEL_SET_DICT, hp_dict=_HYPER_PARAMS_DICT,\n",
    "        loader=_LOADER, gpu_num=_GPU_NUMBER\n",
    "    )\n",
    "    # get DataLoader\n",
    "    MTnE_Ob.train_loader, MTnE_Ob.valid_loader, MTnE_Ob.test_loader\\\n",
    "    = MTnE_Ob.loader.get_all_torch_dataLoader(k)\n",
    "    \n",
    "    # Model 정의\n",
    "    MTnE_Ob.import_model()\n",
    "    # Optimizer(Scheduler, Scaler) 정의\n",
    "    MTnE_Ob.import_optimizer_and_scheduler()\n",
    "    \n",
    "    # 해당 Dataset에 대한 신규 Log file 생성\n",
    "    MTnE_Ob.make_log_file(k)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1/100[============================================================.] (557/557) [time] 0:08:27.32 [Loss] total: 0.0939, classifier: 0.0237, box_reg: 0.0527, objectness: 0.0084, rpn_box_reg: 0.0090\n",
      "Epochs: 2/100[============================================================.] (557/557) [time] 0:08:21.80 [Loss] total: 0.0645, classifier: 0.0153, box_reg: 0.0400, objectness: 0.0024, rpn_box_reg: 0.0067\n",
      "Epochs: 3/100[============================================================.] (557/557) [time] 0:08:22.81 [Loss] total: 0.0624, classifier: 0.0142, box_reg: 0.0380, objectness: 0.0029, rpn_box_reg: 0.0073\n",
      "Epochs: 4/100[============================================================.] (557/557) [time] 0:08:22.46 [Loss] total: 0.0558, classifier: 0.0124, box_reg: 0.0344, objectness: 0.0025, rpn_box_reg: 0.0065\n",
      "Epochs: 5/100[============================================================.] (557/557) [time] 0:08:22.99 [Loss] total: 0.0569, classifier: 0.0128, box_reg: 0.0349, objectness: 0.0026, rpn_box_reg: 0.0066\n",
      "Epochs: 6/100[============================================================.] (557/557) [time] 0:08:21.71 [Loss] total: 0.0627, classifier: 0.0141, box_reg: 0.0376, objectness: 0.0033, rpn_box_reg: 0.0077\n",
      "Epochs: 7/100[============================================================.] (557/557) [time] 0:08:23.43 [Loss] total: 0.0587, classifier: 0.0131, box_reg: 0.0362, objectness: 0.0024, rpn_box_reg: 0.0070\n",
      "Epochs: 8/100[============================================================.] (557/557) [time] 0:08:23.59 [Loss] total: 0.0545, classifier: 0.0126, box_reg: 0.0336, objectness: 0.0023, rpn_box_reg: 0.0060\n",
      "Epochs: 9/100[============================================================.] (557/557) [time] 0:08:23.15 [Loss] total: 0.0496, classifier: 0.0115, box_reg: 0.0310, objectness: 0.0019, rpn_box_reg: 0.0052\n",
      "Epochs: 10/100[============================================================.] (557/557) [time] 0:08:22.41 [Loss] total: 0.0624, classifier: 0.0139, box_reg: 0.0375, objectness: 0.0028, rpn_box_reg: 0.0082\n",
      "Epochs: 11/100[============================================================.] (557/557) [time] 0:08:22.94 [Loss] total: 0.0638, classifier: 0.0143, box_reg: 0.0385, objectness: 0.0029, rpn_box_reg: 0.0081\n",
      "Epochs: 12/100[============================================================.] (557/557) [time] 0:08:25.46 [Loss] total: 0.0610, classifier: 0.0138, box_reg: 0.0372, objectness: 0.0023, rpn_box_reg: 0.0078\n",
      "Epochs: 13/100[============================================================.] (557/557) [time] 0:08:22.73 [Loss] total: 0.0593, classifier: 0.0134, box_reg: 0.0360, objectness: 0.0026, rpn_box_reg: 0.0072\n",
      "Epochs: 14/100[============================================================.] (557/557) [time] 0:08:24.53 [Loss] total: 0.0573, classifier: 0.0131, box_reg: 0.0350, objectness: 0.0022, rpn_box_reg: 0.0070\n",
      "Epochs: 15/100[============================================================.] (557/557) [time] 0:08:24.14 [Loss] total: 0.0539, classifier: 0.0121, box_reg: 0.0332, objectness: 0.0022, rpn_box_reg: 0.0064\n",
      "Epochs: 16/100[============================================================.] (557/557) [time] 0:08:23.30 [Loss] total: 0.0528, classifier: 0.0120, box_reg: 0.0323, objectness: 0.0022, rpn_box_reg: 0.0063\n",
      "Epochs: 17/100[============================================================.] (557/557) [time] 0:08:27.04 [Loss] total: 0.0496, classifier: 0.0113, box_reg: 0.0306, objectness: 0.0021, rpn_box_reg: 0.0057\n",
      "Epochs: 18/100[============================================================.] (557/557) [time] 0:08:23.19 [Loss] total: 0.0486, classifier: 0.0111, box_reg: 0.0298, objectness: 0.0023, rpn_box_reg: 0.0055\n",
      "Epochs: 19/100[============================================================.] (557/557) [time] 0:08:23.07 [Loss] total: 0.0589, classifier: 0.0128, box_reg: 0.0352, objectness: 0.0032, rpn_box_reg: 0.0077\n",
      "Epochs: 20/100[============================================================.] (557/557) [time] 0:08:22.68 [Loss] total: 0.0620, classifier: 0.0136, box_reg: 0.0374, objectness: 0.0027, rpn_box_reg: 0.0083\n",
      "Epochs: 21/100[============================================================.] (557/557) [time] 0:08:24.04 [Loss] total: 0.0604, classifier: 0.0132, box_reg: 0.0360, objectness: 0.0029, rpn_box_reg: 0.0083\n",
      "Epochs: 22/100[============================================================.] (557/557) [time] 0:08:19.91 [Loss] total: 0.0600, classifier: 0.0132, box_reg: 0.0362, objectness: 0.0029, rpn_box_reg: 0.0078\n",
      "Epochs: 23/100[============================================================.] (557/557) [time] 0:08:23.10 [Loss] total: 0.0600, classifier: 0.0130, box_reg: 0.0364, objectness: 0.0026, rpn_box_reg: 0.0079\n",
      "Epochs: 24/100[============================================================.] (557/557) [time] 0:08:23.48 [Loss] total: 0.0575, classifier: 0.0128, box_reg: 0.0349, objectness: 0.0025, rpn_box_reg: 0.0073\n",
      "Epochs: 25/100[============================================================.] (557/557) [time] 0:08:23.60 [Loss] total: 0.0567, classifier: 0.0124, box_reg: 0.0343, objectness: 0.0026, rpn_box_reg: 0.0074\n",
      "Epochs: 26/100[============================================================.] (557/557) [time] 0:08:23.40 [Loss] total: 0.0573, classifier: 0.0124, box_reg: 0.0346, objectness: 0.0032, rpn_box_reg: 0.0072\n",
      "Epochs: 27/100[============================================================.] (557/557) [time] 0:08:20.44 [Loss] total: 0.0557, classifier: 0.0120, box_reg: 0.0337, objectness: 0.0029, rpn_box_reg: 0.0071\n",
      "Epochs: 28/100[============================================================.] (557/557) [time] 0:08:23.09 [Loss] total: 0.0539, classifier: 0.0119, box_reg: 0.0329, objectness: 0.0026, rpn_box_reg: 0.0065\n",
      "Epochs: 29/100[============================================================.] (557/557) [time] 0:08:21.74 [Loss] total: 0.0530, classifier: 0.0116, box_reg: 0.0324, objectness: 0.0025, rpn_box_reg: 0.0065\n",
      "Epochs: 30/100[============================================================.] (557/557) [time] 0:08:23.72 [Loss] total: 0.0522, classifier: 0.0116, box_reg: 0.0317, objectness: 0.0028, rpn_box_reg: 0.0061\n",
      "Epochs: 31/100[============================================================.] (557/557) [time] 0:08:22.19 [Loss] total: 0.0508, classifier: 0.0112, box_reg: 0.0310, objectness: 0.0027, rpn_box_reg: 0.0059\n",
      "Epochs: 32/100[============================================================.] (557/557) [time] 0:08:21.34 [Loss] total: 0.0500, classifier: 0.0109, box_reg: 0.0306, objectness: 0.0026, rpn_box_reg: 0.0059\n",
      "Epochs: 33/100[============================================================.] (557/557) [time] 0:08:21.97 [Loss] total: 0.0496, classifier: 0.0110, box_reg: 0.0300, objectness: 0.0026, rpn_box_reg: 0.0060\n",
      "Epochs: 34/100[============================================================.] (557/557) [time] 0:08:21.41 [Loss] total: 0.0494, classifier: 0.0109, box_reg: 0.0300, objectness: 0.0027, rpn_box_reg: 0.0058\n",
      "Epochs: 35/100[============================================================.] (557/557) [time] 0:08:21.44 [Loss] total: 0.0474, classifier: 0.0106, box_reg: 0.0292, objectness: 0.0024, rpn_box_reg: 0.0053\n",
      "Epochs: 36/100[============================================================.] (557/557) [time] 0:08:21.62 [Loss] total: 0.0474, classifier: 0.0106, box_reg: 0.0289, objectness: 0.0025, rpn_box_reg: 0.0054\n",
      "Epochs: 37/100[============================================================.] (557/557) [time] 0:08:21.70 [Loss] total: 0.0510, classifier: 0.0112, box_reg: 0.0310, objectness: 0.0027, rpn_box_reg: 0.0062\n",
      "Epochs: 38/100[============================================================.] (557/557) [time] 0:08:20.81 [Loss] total: 0.0592, classifier: 0.0126, box_reg: 0.0357, objectness: 0.0031, rpn_box_reg: 0.0077\n",
      "Epochs: 39/100[============================================================.] (557/557) [time] 0:08:18.05 [Loss] total: 0.0589, classifier: 0.0128, box_reg: 0.0355, objectness: 0.0033, rpn_box_reg: 0.0073\n",
      "Epochs: 40/100[============================================================.] (557/557) [time] 0:08:19.94 [Loss] total: 0.0592, classifier: 0.0128, box_reg: 0.0354, objectness: 0.0033, rpn_box_reg: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 41/100[============================================================.] (557/557) [time] 0:08:18.34 [Loss] total: 0.0581, classifier: 0.0126, box_reg: 0.0351, objectness: 0.0029, rpn_box_reg: 0.0075\n",
      "Epochs: 42/100[============================================================.] (557/557) [time] 0:08:21.40 [Loss] total: 0.0579, classifier: 0.0126, box_reg: 0.0350, objectness: 0.0030, rpn_box_reg: 0.0073\n",
      "Epochs: 43/100[============================================================.] (557/557) [time] 0:08:20.84 [Loss] total: 0.0582, classifier: 0.0128, box_reg: 0.0349, objectness: 0.0031, rpn_box_reg: 0.0073\n",
      "Epochs: 44/100[============================================================.] (557/557) [time] 0:08:17.53 [Loss] total: 0.0574, classifier: 0.0122, box_reg: 0.0346, objectness: 0.0035, rpn_box_reg: 0.0071\n",
      "Epochs: 45/100[============================================================.] (557/557) [time] 0:08:18.34 [Loss] total: 0.0569, classifier: 0.0124, box_reg: 0.0343, objectness: 0.0032, rpn_box_reg: 0.0071\n",
      "Epochs: 46/100[============================================================.] (557/557) [time] 0:08:18.82 [Loss] total: 0.0551, classifier: 0.0120, box_reg: 0.0334, objectness: 0.0029, rpn_box_reg: 0.0069\n",
      "Epochs: 47/100[============================================================.] (557/557) [time] 0:08:17.63 [Loss] total: 0.0558, classifier: 0.0120, box_reg: 0.0337, objectness: 0.0030, rpn_box_reg: 0.0071\n",
      "Epochs: 48/100[============================================================.] (557/557) [time] 0:08:16.40 [Loss] total: 0.0549, classifier: 0.0120, box_reg: 0.0334, objectness: 0.0029, rpn_box_reg: 0.0067\n",
      "Epochs: 49/100[============================================================.] (557/557) [time] 0:08:16.99 [Loss] total: 0.0555, classifier: 0.0121, box_reg: 0.0333, objectness: 0.0032, rpn_box_reg: 0.0069\n",
      "Epochs: 50/100[============================================================.] (557/557) [time] 0:08:18.16 [Loss] total: 0.0549, classifier: 0.0119, box_reg: 0.0331, objectness: 0.0029, rpn_box_reg: 0.0070\n",
      "Epochs: 51/100[============================================================.] (557/557) [time] 0:08:18.78 [Loss] total: 0.0546, classifier: 0.0116, box_reg: 0.0326, objectness: 0.0038, rpn_box_reg: 0.0066\n",
      "Epochs: 52/100[============================================================.] (557/557) [time] 0:08:16.80 [Loss] total: 0.0533, classifier: 0.0117, box_reg: 0.0324, objectness: 0.0028, rpn_box_reg: 0.0065\n",
      "Epochs: 53/100[============================================================.] (557/557) [time] 0:08:18.62 [Loss] total: 0.0532, classifier: 0.0114, box_reg: 0.0323, objectness: 0.0029, rpn_box_reg: 0.0065\n",
      "Epochs: 54/100[============================================================.] (557/557) [time] 0:08:16.17 [Loss] total: 0.0515, classifier: 0.0112, box_reg: 0.0315, objectness: 0.0027, rpn_box_reg: 0.0060\n",
      "Epochs: 55/100[============================================================.] (557/557) [time] 0:08:17.17 [Loss] total: 0.0516, classifier: 0.0113, box_reg: 0.0312, objectness: 0.0030, rpn_box_reg: 0.0061\n",
      "Epochs: 56/100[============================================================.] (557/557) [time] 0:08:18.61 [Loss] total: 0.0525, classifier: 0.0112, box_reg: 0.0311, objectness: 0.0037, rpn_box_reg: 0.0065\n",
      "Epochs: 57/100[============================================================.] (557/557) [time] 0:08:15.93 [Loss] total: 0.0516, classifier: 0.0113, box_reg: 0.0310, objectness: 0.0033, rpn_box_reg: 0.0061\n",
      "Epochs: 58/100[============================================================.] (557/557) [time] 0:08:17.91 [Loss] total: 0.0515, classifier: 0.0112, box_reg: 0.0311, objectness: 0.0032, rpn_box_reg: 0.0060\n",
      "Epochs: 59/100[============================================================.] (557/557) [time] 0:08:15.85 [Loss] total: 0.0505, classifier: 0.0109, box_reg: 0.0303, objectness: 0.0032, rpn_box_reg: 0.0060\n",
      "Epochs: 60/100[============================================================.] (557/557) [time] 0:08:18.28 [Loss] total: 0.0493, classifier: 0.0108, box_reg: 0.0298, objectness: 0.0029, rpn_box_reg: 0.0058\n",
      "Epochs: 61/100[============================================================.] (557/557) [time] 0:08:21.41 [Loss] total: 0.0494, classifier: 0.0107, box_reg: 0.0298, objectness: 0.0030, rpn_box_reg: 0.0059\n",
      "Epochs: 62/100[============================================================.] (557/557) [time] 0:08:19.59 [Loss] total: 0.0484, classifier: 0.0105, box_reg: 0.0294, objectness: 0.0030, rpn_box_reg: 0.0055\n",
      "Epochs: 63/100[============================================================.] (557/557) [time] 0:08:20.70 [Loss] total: 0.0489, classifier: 0.0108, box_reg: 0.0296, objectness: 0.0029, rpn_box_reg: 0.0056\n",
      "Epochs: 64/100[============================================================.] (557/557) [time] 0:08:19.23 [Loss] total: 0.0482, classifier: 0.0106, box_reg: 0.0291, objectness: 0.0030, rpn_box_reg: 0.0055\n",
      "Epochs: 65/100[============================================================.] (557/557) [time] 0:08:20.44 [Loss] total: 0.0478, classifier: 0.0104, box_reg: 0.0287, objectness: 0.0032, rpn_box_reg: 0.0055\n",
      "Epochs: 66/100[============================================================.] (557/557) [time] 0:08:21.11 [Loss] total: 0.0475, classifier: 0.0105, box_reg: 0.0285, objectness: 0.0031, rpn_box_reg: 0.0055\n",
      "Epochs: 67/100[============================================================.] (557/557) [time] 0:08:21.11 [Loss] total: 0.0478, classifier: 0.0103, box_reg: 0.0283, objectness: 0.0037, rpn_box_reg: 0.0055\n",
      "Epochs: 68/100[============================================================.] (557/557) [time] 0:08:20.30 [Loss] total: 0.0463, classifier: 0.0101, box_reg: 0.0281, objectness: 0.0028, rpn_box_reg: 0.0053\n",
      "Epochs: 69/100[============================================================.] (557/557) [time] 0:08:19.17 [Loss] total: 0.0464, classifier: 0.0102, box_reg: 0.0283, objectness: 0.0027, rpn_box_reg: 0.0051\n",
      "Epochs: 70/100[============================================================.] (557/557) [time] 0:08:19.76 [Loss] total: 0.0459, classifier: 0.0101, box_reg: 0.0276, objectness: 0.0031, rpn_box_reg: 0.0052\n",
      "Epochs: 71/100[============================================================.] (557/557) [time] 0:08:20.49 [Loss] total: 0.0463, classifier: 0.0102, box_reg: 0.0278, objectness: 0.0029, rpn_box_reg: 0.0054\n",
      "Epochs: 72/100[============================================================.] (557/557) [time] 0:08:20.61 [Loss] total: 0.0464, classifier: 0.0102, box_reg: 0.0281, objectness: 0.0029, rpn_box_reg: 0.0052\n",
      "Epochs: 73/100[============================================================.] (557/557) [time] 0:08:21.39 [Loss] total: 0.0460, classifier: 0.0101, box_reg: 0.0279, objectness: 0.0029, rpn_box_reg: 0.0051\n",
      "Epochs: 74/100[============================================================.] (557/557) [time] 0:08:20.37 [Loss] total: 0.0525, classifier: 0.0113, box_reg: 0.0313, objectness: 0.0031, rpn_box_reg: 0.0068\n",
      "Epochs: 75/100[============================================================.] (557/557) [time] 0:08:21.86 [Loss] total: 0.0558, classifier: 0.0119, box_reg: 0.0334, objectness: 0.0036, rpn_box_reg: 0.0069\n",
      "Epochs: 76/100[============================================================.] (557/557) [time] 0:08:20.58 [Loss] total: 0.0565, classifier: 0.0120, box_reg: 0.0338, objectness: 0.0036, rpn_box_reg: 0.0071\n",
      "Epochs: 77/100[============================================================.] (557/557) [time] 0:08:21.67 [Loss] total: 0.0560, classifier: 0.0120, box_reg: 0.0336, objectness: 0.0035, rpn_box_reg: 0.0070\n",
      "Epochs: 78/100[============================================================.] (557/557) [time] 0:08:21.60 [Loss] total: 0.0555, classifier: 0.0117, box_reg: 0.0329, objectness: 0.0037, rpn_box_reg: 0.0071\n",
      "Epochs: 79/100[============================================================.] (557/557) [time] 0:08:20.47 [Loss] total: 0.0551, classifier: 0.0118, box_reg: 0.0333, objectness: 0.0032, rpn_box_reg: 0.0068\n",
      "Epochs: 80/100[============================================================.] (557/557) [time] 0:08:21.26 [Loss] total: 0.0553, classifier: 0.0120, box_reg: 0.0333, objectness: 0.0033, rpn_box_reg: 0.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 81/100[============================================================.] (557/557) [time] 0:08:21.39 [Loss] total: 0.0552, classifier: 0.0120, box_reg: 0.0332, objectness: 0.0033, rpn_box_reg: 0.0067\n",
      "Epochs: 82/100[============================================================.] (557/557) [time] 0:08:19.29 [Loss] total: 0.0561, classifier: 0.0123, box_reg: 0.0334, objectness: 0.0035, rpn_box_reg: 0.0070\n",
      "Epochs: 83/100[============================================================.] (557/557) [time] 0:08:22.83 [Loss] total: 0.0553, classifier: 0.0119, box_reg: 0.0332, objectness: 0.0032, rpn_box_reg: 0.0069\n",
      "Epochs: 84/100[============================================================.] (557/557) [time] 0:08:20.70 [Loss] total: 0.0548, classifier: 0.0120, box_reg: 0.0330, objectness: 0.0032, rpn_box_reg: 0.0066\n",
      "Epochs: 85/100[============================================================.] (557/557) [time] 0:08:21.88 [Loss] total: 0.0539, classifier: 0.0117, box_reg: 0.0324, objectness: 0.0032, rpn_box_reg: 0.0065\n",
      "Epochs: 86/100[============================================================.] (557/557) [time] 0:08:21.61 [Loss] total: 0.0546, classifier: 0.0118, box_reg: 0.0330, objectness: 0.0032, rpn_box_reg: 0.0067\n",
      "Epochs: 87/100[============================================================.] (557/557) [time] 0:08:21.35 [Loss] total: 0.0552, classifier: 0.0120, box_reg: 0.0330, objectness: 0.0035, rpn_box_reg: 0.0068\n",
      "Epochs: 88/100[============================================================.] (557/557) [time] 0:08:18.58 [Loss] total: 0.0543, classifier: 0.0118, box_reg: 0.0327, objectness: 0.0032, rpn_box_reg: 0.0066\n",
      "Epochs: 89/100[============================================================.] (557/557) [time] 0:08:19.92 [Loss] total: 0.0541, classifier: 0.0117, box_reg: 0.0323, objectness: 0.0036, rpn_box_reg: 0.0066\n",
      "Epochs: 90/100[============================================================.] (557/557) [time] 0:08:21.23 [Loss] total: 0.0549, classifier: 0.0117, box_reg: 0.0328, objectness: 0.0035, rpn_box_reg: 0.0069\n",
      "Epochs: 91/100[============================================================.] (557/557) [time] 0:08:19.54 [Loss] total: 0.0540, classifier: 0.0116, box_reg: 0.0324, objectness: 0.0036, rpn_box_reg: 0.0064\n",
      "Epochs: 92/100[============================================================.] (557/557) [time] 0:08:20.94 [Loss] total: 0.0545, classifier: 0.0118, box_reg: 0.0324, objectness: 0.0036, rpn_box_reg: 0.0065\n",
      "Epochs: 93/100[============================================================.] (557/557) [time] 0:08:20.50 [Loss] total: 0.0531, classifier: 0.0114, box_reg: 0.0321, objectness: 0.0031, rpn_box_reg: 0.0066\n",
      "Epochs: 94/100[============================================================.] (557/557) [time] 0:08:20.69 [Loss] total: 0.0533, classifier: 0.0116, box_reg: 0.0323, objectness: 0.0030, rpn_box_reg: 0.0065\n",
      "Epochs: 95/100[============================================================.] (557/557) [time] 0:08:20.21 [Loss] total: 0.0528, classifier: 0.0115, box_reg: 0.0318, objectness: 0.0032, rpn_box_reg: 0.0062\n",
      "Epochs: 96/100[============================================================.] (557/557) [time] 0:08:19.75 [Loss] total: 0.0535, classifier: 0.0113, box_reg: 0.0316, objectness: 0.0040, rpn_box_reg: 0.0065\n",
      "Epochs: 97/100[============================================================.] (557/557) [time] 0:08:21.23 [Loss] total: 0.0525, classifier: 0.0115, box_reg: 0.0317, objectness: 0.0031, rpn_box_reg: 0.0063\n",
      "Epochs: 98/100[============================================================.] (557/557) [time] 0:08:23.05 [Loss] total: 0.0527, classifier: 0.0113, box_reg: 0.0317, objectness: 0.0034, rpn_box_reg: 0.0063\n",
      "Epochs: 99/100[============================================================.] (557/557) [time] 0:08:22.59 [Loss] total: 0.0520, classifier: 0.0113, box_reg: 0.0313, objectness: 0.0030, rpn_box_reg: 0.0063\n",
      "Epochs: 100/100[============================================================.] (557/557) [time] 0:08:20.02 [Loss] total: 0.0533, classifier: 0.0114, box_reg: 0.0319, objectness: 0.0037, rpn_box_reg: 0.0063\n",
      "CPU times: user 11h 13min 49s, sys: 4h 25min 46s, total: 15h 39min 36s\n",
      "Wall time: 13h 54min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(MTnE_Ob.m_set_dict[\"epochs\"]):\n",
    "    \n",
    "    # Model training\n",
    "    Loss_Ins = MTnE_Ob.model_train_process(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model을 가지고 온다.\n",
    "# model = get_model_FineTuning_classSize()\n",
    "\n",
    "# # train model\n",
    "# imgs, targets = next(iter(train_loader))\n",
    "# output = model(imgs, targets)   # Returns losses and detections\n",
    "\n",
    "# # model predict\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_e2",
   "language": "python",
   "name": "dev_e2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
