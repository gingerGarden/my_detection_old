{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Module.Global_variable import os, time, torch, np, pd, plt, K_SIZE\n",
    "from Module.Convenience_Function import save_pickle, draw_img_and_bbox_torch_style\n",
    "from Module.Convenience_Function_by_torch import state_dict_to_np_array_dict\n",
    "\n",
    "from Module.process1_index_dictionary_maker import get_index_dictionary\n",
    "from Module.process1_torch_basic_style_model import get_my_torch_model, get_optimizer\n",
    "from Module.process1_main_process import setting_dict, pixed_hyperParameter_dict, hyperParameter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from Module import utils\n",
    "from Module.Convenience_Function import progressbar, time_checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `torch._dynamo`의 캐시 한계를 늘림.\n",
    "## Pytorch의 동적 컴파일러 설정 조정.\n",
    "## 기본 캐시 크기인 64를 128로 늘림.\n",
    "## 캐시에 저장할 수 있는 최적화된 코드 조각들의 최대 개수를 의미함.\n",
    "## 확인 결과 RAM의 buff/cache memory에 할당되는 것 확인.\n",
    "## 512 설정 시, 4GB 가량 늘어났음 buff/cache 172G -> 176G\n",
    "torch._dynamo.config.cache_size_limit = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변동 가능한 전역 변수\n",
    "########################################################\n",
    "# Index dictionary를 새로 만들 것인지.\n",
    "MAKE_NEW_INDEX_DICT = False\n",
    "########################################################\n",
    "\n",
    "\n",
    "# Process 초기값 설정\n",
    "########################################################\n",
    "GPU_NUMBER = 3\n",
    "\n",
    "torch.cuda.set_device(GPU_NUMBER)\n",
    "process_key_dict=dict()\n",
    "process_key_dict[\"setting\"]=setting_dict(\n",
    "    model_key=\"basic_model\",\n",
    "    gpu_number=GPU_NUMBER,\n",
    "    idx_dict=get_index_dictionary(process_boolean=MAKE_NEW_INDEX_DICT).process(),\n",
    "    optimizer=\"Adam\",\n",
    "    verbose=True\n",
    ")\n",
    "process_key_dict[\"pixed_hyperParameter\"]=pixed_hyperParameter_dict()\n",
    "process_key_dict[\"hyperParameter\"]=hyperParameter_dict(\n",
    "    learing_rate=0.001, \n",
    "    weight_decay=0.05,\n",
    "    T_0=20,\n",
    "    T_mult=2,\n",
    "    eta_min=0.000001\n",
    ")\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_training_process:\n",
    "    \n",
    "    def __init__(self, key_dict, use_torch2_compile=False):\n",
    "        \n",
    "        self.setting_dict = key_dict[\"setting\"]\n",
    "        self.pixed_hp_dict = key_dict[\"pixed_hyperParameter\"]\n",
    "        self.hp_dict = key_dict[\"hyperParameter\"]\n",
    "        self.use_torch2_compile = use_torch2_compile\n",
    "        \n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "        self.test_loader = None\n",
    "        \n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.scaler = None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def Load_k_fold_dataLoader(self, k):\n",
    "        \n",
    "        # Data Loader들을 가지고 온다.\n",
    "        self.train_loader, self.valid_loader, self.test_loader =\\\n",
    "        self.setting_dict[\"loader\"].get_all_torch_dataLoader(k)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def Load_model_and_optimizer(self):\n",
    "        \n",
    "        # Model을 가지고 온다.\n",
    "        model = get_my_torch_model(\n",
    "            class_num=self.setting_dict[\"num_class\"], key=self.setting_dict[\"model_key\"]\n",
    "        ).process().to(self.setting_dict[\"device\"])\n",
    "        # torch 2.0의 compile을 사용할지 여부.\n",
    "        self.model = torch.compile(model) if self.use_torch2_compile else model\n",
    "        \n",
    "        # Optimizer 정의\n",
    "        self.optimizer = get_optimizer(\n",
    "            self.model,\n",
    "            learning_Rate=self.hp_dict[\"learning_rate\"],\n",
    "            weight_decay=self.hp_dict[\"weight_decay\"],\n",
    "            opt_key=self.setting_dict[\"optimizer\"]\n",
    "        )\n",
    "        # Scheduler 정의\n",
    "        self.scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer=self.optimizer,\n",
    "            T_0=self.hp_dict[\"T_0\"],\n",
    "            T_mult=self.hp_dict[\"T_mult\"],\n",
    "            eta_min=self.hp_dict[\"eta_min\"]\n",
    "        )\n",
    "        # scaler 정의 - AMP를 위하여\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def data_upload_to_device(self, image_list, target_list):\n",
    "        \n",
    "        # 모든 image들을 device에 올린다.\n",
    "        stack_device_imgs = []\n",
    "        for image in image_list:\n",
    "            stack_device_imgs.append(image.to(self.setting_dict[\"device\"]))\n",
    "\n",
    "        # 모든 target들을 device에 올린다(Tensor로 출력되지 않은 id는 제외).\n",
    "        stack_device_targets = []\n",
    "        for target in target_list:\n",
    "            device_target = dict()\n",
    "            for key, value in target.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    device_target[key] = value.to(self.setting_dict[\"device\"])\n",
    "                else:\n",
    "                    device_target[key] = value\n",
    "            stack_device_targets.append(device_target)\n",
    "            \n",
    "        return stack_device_imgs, stack_device_targets\n",
    "    \n",
    "    \n",
    "    \n",
    "    def gradients_scaling_with_clipping(self, losses):\n",
    "        # 그라디언트 스케일링 및 역전파\n",
    "        self.scaler.scale(losses).backward()\n",
    "        # Gadient update 전에 Gradient clipping 적용\n",
    "        ###############################################################################\n",
    "        ## AMP 사용 시, Gradient clipping은 Scaling 역산 후 수행되어야 함\n",
    "        self.scaler.unscale_(self.optimizer)  # 스케일링 역산\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            self.model.parameters(), max_norm=self.pixed_hp_dict[\"max_norm\"]\n",
    "        )\n",
    "        ###############################################################################\n",
    "        # 스케일링된 그라디언트로 파라미터 업데이트\n",
    "        self.scaler.step(self.optimizer)\n",
    "        # 스케일러 업데이트\n",
    "        self.scaler.update()\n",
    "\n",
    "\n",
    "        \n",
    "    def normal_gradient_descent_with_clipping(self, losses):\n",
    "        losses.backward()\n",
    "        # Gadient update 전에 Gradient clipping 적용\n",
    "        ###############################################################################\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            self.model.parameters(), max_norm=self.pixed_hp_dict[\"max_norm\"]\n",
    "        )\n",
    "        ###############################################################################\n",
    "        # gradient update\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K_SIZE):\n",
    "    \n",
    "    # Model 학습을 위한 Instance 생성\n",
    "    MT_Ob = model_training_process(key_dict=process_key_dict, use_torch2_compile=False)\n",
    "    # k-fold에 해당하는 Data Loader를 가지고 온다.\n",
    "    MT_Ob.Load_k_fold_dataLoader(k)\n",
    "    # Model, Optimizer, Scheduler 등 설정\n",
    "    MT_Ob.Load_model_and_optimizer()\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_epoch = MT_Ob.pixed_hp_dict['epochs']\n",
    "for epoch in range(MT_Ob.pixed_hp_dict[\"epochs\"]):\n",
    "    print(f\"Epoch: {epoch} / {max_epoch}\")\n",
    "    \n",
    "    # model을 학습 상태로 정의\n",
    "    MT_Ob.model.train()\n",
    "\n",
    "    #####################################################################################\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "    header = f\"Epoch: [{epoch}]\"\n",
    "    #####################################################################################\n",
    "\n",
    "    iteration_num = 0\n",
    "    for imgs, targets, in metric_logger.log_every(MT_Ob.train_loader, print_freq, header):\n",
    "    # for imgs, targets, in progressbar(MT_Ob.train_loader, prefix=f\"iteration: \", verbose=MT_Ob.setting_dict[\"verbose\"]):\n",
    "\n",
    "        start_iter = time.time()\n",
    "\n",
    "        # 학습에 사용될 데이터들을 device로 올린다.\n",
    "        imgs, targets = MT_Ob.data_upload_to_device(imgs, targets)\n",
    "        # 자동혼합정밀도(AMP)의 autocast 사용 여부\n",
    "        with torch.cuda.amp.autocast(enabled=MT_Ob.setting_dict[\"use_amp\"]):\n",
    "            loss_dict = MT_Ob.model(imgs, targets)\n",
    "            # loss_dict에 있는 모든 loss(loss_classification, loss_box_reg, loss_objectness, loss_rpn_box_reg)의 값들을 합친다.\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        ###################################################################################\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping training\")\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "        ###################################################################################\n",
    "\n",
    "\n",
    "        # 손실값을 기반으로 경사 하강 실시.\n",
    "        MT_Ob.optimizer.zero_grad()\n",
    "        # GradScaler를 적용하여, Autocast 사용 시 발생할 수 있는 Underflow나 Overflow 문제 완화\n",
    "        if MT_Ob.setting_dict[\"use_amp\"]:\n",
    "            MT_Ob.gradients_scaling_with_clipping(losses)\n",
    "        else:\n",
    "            MT_Ob.normal_gradient_descent_with_clipping(losses)\n",
    "\n",
    "        # CosineAnnealingWarmRestarts를 사용하였으므로, Iteration 안에서 적용\n",
    "        MT_Ob.scheduler.step()\n",
    "\n",
    "        ######################################################################################\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=MT_Ob.optimizer.param_groups[0][\"lr\"])\n",
    "        ######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ######################################################################################\n",
    "        print(f\"{iteration_num}: {time_checker(start_iter)}\")\n",
    "        iteration_num += 1\n",
    "        ######################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # model을 학습 상태로 정의\n",
    "# MT_Ob.model.train()\n",
    "\n",
    "# #####################################################################################\n",
    "# metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "# metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "# header = f\"Epoch: [{epoch}]\"\n",
    "# #####################################################################################\n",
    "\n",
    "# iteration_num = 0\n",
    "# for imgs, targets, in metric_logger.log_every(MT_Ob.train_loader, print_freq, header):\n",
    "# # for imgs, targets, in progressbar(MT_Ob.train_loader, prefix=f\"iteration: \", verbose=MT_Ob.setting_dict[\"verbose\"]):\n",
    "    \n",
    "#     # 학습에 사용될 데이터들을 device로 올린다.\n",
    "#     imgs, targets = MT_Ob.data_upload_to_device(imgs, targets)\n",
    "#     # 자동혼합정밀도(AMP)의 autocast 사용 여부\n",
    "#     with torch.cuda.amp.autocast(enabled=MT_Ob.setting_dict[\"use_amp\"]):\n",
    "#         loss_dict = MT_Ob.model(imgs, targets)\n",
    "#         # loss_dict에 있는 모든 loss(loss_classification, loss_box_reg, loss_objectness, loss_rpn_box_reg)의 값들을 합친다.\n",
    "#         losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "#     ###################################################################################\n",
    "#     # reduce losses over all GPUs for logging purposes\n",
    "#     loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "#     losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "#     loss_value = losses_reduced.item()\n",
    "\n",
    "#     if not math.isfinite(loss_value):\n",
    "#         print(f\"Loss is {loss_value}, stopping training\")\n",
    "#         print(loss_dict_reduced)\n",
    "#         sys.exit(1)\n",
    "#     ###################################################################################\n",
    "    \n",
    "        \n",
    "#     # 손실값을 기반으로 경사 하강 실시.\n",
    "#     MT_Ob.optimizer.zero_grad()\n",
    "#     # GradScaler를 적용하여, Autocast 사용 시 발생할 수 있는 Underflow나 Overflow 문제 완화\n",
    "#     if MT_Ob.setting_dict[\"use_amp\"]:\n",
    "#         MT_Ob.gradients_scaling_with_clipping(losses)\n",
    "#     else:\n",
    "#         MT_Ob.normal_gradient_descent_with_clipping(losses)\n",
    "\n",
    "#     # CosineAnnealingWarmRestarts를 사용하였으므로, Iteration 안에서 적용\n",
    "#     MT_Ob.scheduler.step()\n",
    "    \n",
    "#     ######################################################################################\n",
    "#     metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "#     metric_logger.update(lr=MT_Ob.optimizer.param_groups[0][\"lr\"])\n",
    "#     ######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model을 가지고 온다.\n",
    "# model = get_model_FineTuning_classSize()\n",
    "\n",
    "# # train model\n",
    "# imgs, targets = next(iter(train_loader))\n",
    "# output = model(imgs, targets)   # Returns losses and detections\n",
    "\n",
    "# # model predict\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_e2",
   "language": "python",
   "name": "dev_e2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
